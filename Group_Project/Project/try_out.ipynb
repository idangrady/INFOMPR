{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.layers import Input, LSTM, Attention, Embedding, Dense, Concatenate, TimeDistributed   #Layers required to implement the model\n",
    "# Try out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np   #Package for scientific computing and dealing with arrays\n",
    "import pandas as pd  #Package providing fast, flexible and expressive data structures\n",
    "import re            #re stands for RegularExpression providing full support for Perl-like Regular Expressions in Python\n",
    "from bs4 import BeautifulSoup   #Package for pulling data out of HTML and XML files\n",
    "from keras.preprocessing.sequence import pad_sequences  #For Padding the seqences to same length\n",
    "from nltk.corpus import stopwords   #For removing filler words\n",
    "from tensorflow.keras.layers import Input, LSTM, Attention, Embedding, Dense, Concatenate, TimeDistributed   #Layers required to implement the model\n",
    "from tensorflow.keras.models import Model  #Helps in grouping the layers into an object with training and inference features\n",
    "from tensorflow.keras.callbacks import EarlyStopping  #Allows training the model on large no. of training epochs & stop once the performance stops improving on validation dataset\n",
    "from os import listdir\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loaded Stories 23\n"
    }
   ],
   "source": [
    "\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, encoding='utf-8')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "# split a document into news story and highlights\n",
    "def split_story(doc):\n",
    "\t# find first highlight\n",
    "\tindex = doc.find('@highlight')\n",
    "\t# split into story and highlights\n",
    "\tstory, highlights = doc[:index], doc[index:].split('@highlight')\n",
    "\t# strip extra white space around each highlight\n",
    "\thighlights = [h.strip() for h in highlights if len(h) > 0]\n",
    "\treturn story, highlights\n",
    "\n",
    "# load all stories in a directory\n",
    "def load_stories(directory):\n",
    "\tstories = list()\n",
    "\tfor name in listdir(directory):\n",
    "\t\tfilename = directory + '/' + name\n",
    "\t\t# load document\n",
    "\t\tdoc = load_doc(filename)\n",
    "\t\t# split into story and highlights\n",
    "\t\tstory, highlights = split_story(doc)\n",
    "\t\t# store\n",
    "\t\tstories.append({'story':story, 'highlights':highlights})\n",
    "\treturn stories\n",
    "\n",
    "# clean a list of lines\n",
    "def clean_lines(lines):\n",
    "\tcleaned = list()\n",
    "\t# prepare a translation table to remove punctuation\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\tfor line in lines:\n",
    "\t\t# strip source cnn office if it exists\n",
    "\t\tindex = line.find('(CNN) -- ')\n",
    "\t\tif index > -1:\n",
    "\t\t\tline = line[index+len('(CNN)'):]\n",
    "\t\t# tokenize on white space\n",
    "\t\tline = line.split()\n",
    "\t\t# convert to lower case\n",
    "\t\tline = [word.lower() for word in line]\n",
    "\t\t# remove punctuation from each token\n",
    "\t\tline = [w.translate(table) for w in line]\n",
    "\t\t# remove tokens with numbers in them\n",
    "\t\tline = [word for word in line if word.isalpha()]\n",
    "\t\t# store as string\n",
    "\t\tcleaned.append(' '.join(line))\n",
    "\t# remove empty strings\n",
    "\tcleaned = [c for c in cleaned if len(c) > 0]\n",
    "\treturn cleaned\n",
    "\n",
    "# load stories\n",
    "directory = 'cnn/'\n",
    "stories = load_stories(directory)\n",
    "print('Loaded Stories %d' % len(stories))\n",
    "\n",
    "# clean stories\n",
    "for example in stories:\n",
    "\texample['story'] = clean_lines(example['story'].split('\\n'))\n",
    "\texample['highlights'] = clean_lines(example['highlights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "from pickle import dump\n",
    "dump(stories, open('cnn_dataset.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loaded Stories 23\n"
    }
   ],
   "source": [
    "from pickle import load\n",
    "\n",
    "# load from file\n",
    "stories = load(open('cnn_dataset.pkl', 'rb'))\n",
    "print('Loaded Stories %d' % len(stories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import RepeatVector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['after a weekend of intense investigation authorities are piecing together more details about friday s fatal shooting at los angeles international airport including the suspect s behavior earlier in the week and a warning from his family that may have come minutes too late',\n 'officers sent to check on paul ciancia s welfare arrived at his apartment less than an hour after the shooting started police said monday',\n 'here is a rundown to get you up to speed',\n 'the suspect',\n 'ciancia of los angeles is charged with murder of a federal officer and commission of violence in an international airport',\n 'he was shot by officers friday and was in critical condition at ronald reagan ucla medical center on sunday',\n 'a source said ciancia was unable to speak to investigators',\n 'clues about a motive',\n 'attorney general eric holder said monday that more investigation is necessary to uncover a motive for the attack',\n 'but a note found on ciancia indicated that he wanted to kill transportation security administration employees to instill fear in what the suspect called the agents traitorous minds fbi special agent in charge david bowdich said',\n 'according to someone who knew ciancia and his three roommates well ciancia began asking for a ride to the airport days before the shooting he claimed he needed to fly to new jersey to help his sick father but he never said what day he needed to leave the source said',\n 'on friday ciancia burst into a roommate s room and demanded a ride to the airport immediately said the source who spoke to cnn on the condition of anonymity',\n 'the roommate obliged investigators do nt think the roommate had any idea of ciancia s plans',\n 'the nearsave',\n 'around the same time ciancia was sending text messages to family members in pennsville new jersey',\n 'one suggested that something bad would happen',\n 'although ciancia has no known history of mental illness he said in the texts that he was unhappy and the messages were alarming enough that ciancia s father decided to call police',\n 'i felt that it was pretty serious it sounded as if paul ciancia in california was thinking about harming himself so obviously i knew i needed to make a phone call to the lapd pennsville police chief allen cummings told cnn s jake tapper on monday',\n 'cummings spoke with a lieutenant there who told him the department was in the middle of responding to a shooting at lax',\n 'at this point we were nt connecting the dots he said they did later when a reporter called the police chief asking him to comment on the shooting',\n 'los angeles police department cmdr andy smith says police were first called to check on ciancia at am officers arrived at his apartment six minutes later according to smith',\n 'ciancia was already gone',\n 'the timeline provided monday by police differed from that offered earlier by rep michael mccaul rtexas chairman of the house homeland security committee he said police had arrived at ciancia s apartment about minutes after the suspect had left for the airport',\n 'according to the lapd account they arrived minutes after the shooting which began about am according to police it was not immediately clear when ciancia left for the airport',\n 'the attack',\n 'about am friday ciancia walked up to a transportation security administration checkpoint in terminal he pulled a caliber assault rifle from a bag and shot tsa officer gerardo hernandez at pointblank range according to a court document filed by an fbi agent',\n 'ciancia then went up an escalator but returned to shoot hernandez again apparently after seeing him move',\n 'he continued walking and shooting witnesses said he went from person to person asking are you tsa',\n 'i just shook my head traveler leon saryan told cnn s anderson cooper and he kept going',\n 'chaos and terror inside lax terminal',\n 'the victims',\n 'hernandez was the first tsa officer to die in the line of duty since the agency was created in',\n 'he took pride in his duty for the american public and for the tsa mission said his wife ana hernandez',\n 'the couple who married in have two children',\n 'two other tsa officers james speer and tony grigsby were wounded but were released from the hospital',\n 'grigsby who was shot in the foot told reporters monday he was injured while helping an elderly man move to a safe area',\n 'i turned around and there was a gunman he said shot me twice',\n 'a traveler who was shot in the leg brian ludmer of lake forest illinois was in fair condition sunday',\n 'the police response',\n 'tsa officers are unarmed so it was airport police officers who eventually shot ciancia multiple times in the chest also striking him in the face and neck',\n 'airport police chief patrick gannon said the fbi told him that his officers were seconds behind ciancia he praised their response even though he acknowledged that he had moved his officers away from positions inside the checkpoints during the past year',\n 'the threat at the airport does not exist behind security at that podium the threat exists from the curbline on gannon said so we have our people stationed throughout the airport',\n 'holder said monday that the investigation will include a review of security measures at lax and other airports',\n 'the responsibility for protecting airport security is not a tsa function but something that i think we need to certainly examine given what happened in los angeles he said',\n 'travel delays',\n 'the incident forced authorities to shut down parts of the airport evacuate travelers and put a temporary hold on some departures and landings',\n 'more than airline passengers were affected by the incident friday as a result of cancellations delays or diversions to other airports according to lax one airline jetblue temporarily moved its operations to long beach airport',\n 'on saturday an additional flights were affected including that were canceled involving about passengers according to los angeles international airport',\n 'according to flightaware a flight tracking website airlines canceled flights into or out of lax after the incident friday morning and more saturday',\n 'an additional flights were delayed over the two days flightaware said',\n 'some of those cancellations and delays may have been caused by problems other than the shooting however',\n 'the airport was operating normally monday morning',\n 'suspect s family responds',\n 'ciancia s family in a statement read monday afternoon by attorney john jordan in new jersey said they were shocked and numbed by the tragic events of last friday',\n 'it is most important for us as a family to express our deep and sincere sympathy to the hernandez family the ciancia family said lrb by rrb all accounts officer hernandez was an exemplary member of the law enforcement community and a good family man our hearts go out to his family and many others who grieve his passing',\n 'we wish to convey too our hopes that those who were wounded during this incident will experience quick and full recoveries we also regret the inconvenience experienced by thousands of travelers as well as the administration and the employees of the los angeles airport',\n 'the ciancia family said they would continue to love and care for paul',\n 'we will support him during the difficult times ahead while we do not mean to minimize the grief and distress experienced by many other families we hope that the public will understand that this is a very difficult time for our family too the family said',\n 'what s next',\n 'if convicted ciancia could face the death penalty or life in prison without parole the us attorney general would decide whether to pursue a death sentence',\n 'tsa administrator john pistole said the shooting has prompted a review of security protocol with partner agencies',\n 'mccaul said better coordination with local law enforcement could improve security at checkpoints',\n 'but the congressman acknowledged that it s very difficult to stop these types of attacks',\n 'it s almost like an open shopping mall he said',\n 'opinion do nt arm the tsa']"
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "(stories[0]['story'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "\n",
    "#This the dictionary used for expanding contractions\n",
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\n",
    "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n[nltk_data]     unable to get local issuer certificate (_ssl.c:1108)>\n"
    }
   ],
   "source": [
    "#Text Cleaning\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "def text_cleaner(text,num):\n",
    "    newString = text.lower()  #converts all uppercase characters in the string into lowercase characters and returns it\n",
    "    newString = BeautifulSoup(newString, \"lxml\").text #parses the string into an lxml.html \n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString) #used to replace a string that matches a regular expression instead of perfect match\n",
    "    newString = re.sub('\"','', newString)           \n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")]) #for expanding contractions using the contraction_mapping dictionary    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
    "    if(num==0): \n",
    "      tokens = [w for w in newString.split() if not w in stop_words]  #converting the strings into tokens\n",
    "    else :\n",
    "      tokens = newString.split()\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                  #removing short words\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'idan': 1}"
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "ss  = edict()\n",
    "ss[\"idan\"] = 1\n",
    "ss[\"idan\"]+1\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the function\n",
    "x_vocab = edict()\n",
    "y_vocab = edict()\n",
    "\n",
    "article_word_count = []\n",
    "abstract_word_count = []\n",
    "\n",
    "cleaned_text = []\n",
    "highlights = []\n",
    "\n",
    "max_ar_length = 0\n",
    "max_high_lengh = 0\n",
    "\n",
    "for file in stories:\n",
    "    t = file['story']\n",
    "    story =\"\"\n",
    "    highligh= \"\"\n",
    "    h = file['highlights']\n",
    "    for line in t:\n",
    "        story= story+line\n",
    "        for word in line: \n",
    "            if word not in x_vocab.keys():\n",
    "                x_vocab[word] =1\n",
    "            else: \n",
    "                x_vocab[word]+=1\n",
    "\n",
    "    if len(story.split())> max_ar_length: max_ar_length =len(story.split())\n",
    "    article_word_count.append(len(story.split()))\n",
    "    cleaned_text.append(text_cleaner(story,0))\n",
    "    for line in h:\n",
    "        highligh= highligh+line\n",
    "        if word not in y_vocab.keys():\n",
    "            y_vocab[word] =1\n",
    "        else: \n",
    "            y_vocab[word]+=1\n",
    "\n",
    "    if len(highligh.split())> max_high_lengh: max_high_lengh =len(highligh.split())\n",
    "    abstract_word_count.append(len(highligh.split()))\n",
    "    highlights.append(highligh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Max length sequence story: 1329\n Max length sequence story: 56\n"
    }
   ],
   "source": [
    "# print summer: \n",
    "print(f\" Max length sequence story: {max_ar_length}\")\n",
    "print(f\" Max length sequence story: {max_high_lengh}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "int"
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "type(len(set(cleaned_text[1].split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'weekend intense investigation authorities piecing together details friday fatal shooting los angeles international airport including suspect behavior earlier week warning family may come minutes lateofficers sent check paul ciancia welfare arrived apartment less hour shooting started police said mondayhere rundown get speedthe suspectciancia los angeles charged murder federal officer commission violence international airporthe shot officers friday critical condition ronald reagan ucla medical center sundaya source said ciancia unable speak investigatorsclues motiveattorney general eric holder said monday investigation necessary uncover motive attackbut note found ciancia indicated wanted kill transportation security administration employees instill fear suspect called agents traitorous minds fbi special agent charge david bowdich saidaccording someone knew ciancia three roommates well ciancia began asking ride airport days shooting claimed needed fly new jersey help sick father never said day needed leave source saidon friday ciancia burst roommate room demanded ride airport immediately said source spoke cnn condition anonymitythe roommate obliged investigators nt think roommate idea ciancia plansthe nearsavearound time ciancia sending text messages family members pennsville new jerseyone suggested something bad would happenalthough ciancia known history mental illness said texts unhappy messages alarming enough ciancia father decided call policei felt pretty serious sounded paul ciancia california thinking harming obviously knew needed make phone call lapd pennsville police chief allen cummings told cnn jake tapper mondaycummings spoke lieutenant told department middle responding shooting laxat point nt connecting dots said later reporter called police chief asking comment shootinglos angeles police department cmdr andy smith says police first called check ciancia officers arrived apartment six minutes later according smithciancia already gonethe timeline provided monday police differed offered earlier rep michael mccaul rtexas chairman house homeland security committee said police arrived ciancia apartment minutes suspect left airportaccording lapd account arrived minutes shooting began according police immediately clear ciancia left airportthe attackabout friday ciancia walked transportation security administration checkpoint terminal pulled caliber assault rifle bag shot tsa officer gerardo hernandez pointblank range according court document filed fbi agentciancia went escalator returned shoot hernandez apparently seeing movehe continued walking shooting witnesses said went person person asking tsai shook head traveler leon saryan told cnn anderson cooper kept goingchaos terror inside lax terminalthe victimshernandez first tsa officer die line duty since agency created inhe took pride duty american public tsa mission said wife ana hernandezthe couple married two childrentwo tsa officers james speer tony grigsby wounded released hospitalgrigsby shot foot told reporters monday injured helping elderly man move safe areai turned around gunman said shot twicea traveler shot leg brian ludmer lake forest illinois fair condition sundaythe police responsetsa officers unarmed airport police officers eventually shot ciancia multiple times chest also striking face neckairport police chief patrick gannon said fbi told officers seconds behind ciancia praised response even though acknowledged moved officers away positions inside checkpoints past yearthe threat airport exist behind security podium threat exists curbline gannon said people stationed throughout airportholder said monday investigation include review security measures lax airportsthe responsibility protecting airport security tsa function something think need certainly examine given happened los angeles saidtravel delaysthe incident forced authorities shut parts airport evacuate travelers put temporary hold departures landingsmore airline passengers affected incident friday result cancellations delays diversions airports according lax one airline jetblue temporarily moved operations long beach airporton saturday additional flights affected including canceled involving passengers according los angeles international airportaccording flightaware flight tracking website airlines canceled flights lax incident friday morning saturdayan additional flights delayed two days flightaware saidsome cancellations delays may caused problems shooting howeverthe airport operating normally monday morningsuspect family respondsciancia family statement read monday afternoon attorney john jordan new jersey said shocked numbed tragic events last fridayit important us family express deep sincere sympathy hernandez family ciancia family said lrb rrb accounts officer hernandez exemplary member law enforcement community good family man hearts go family many others grieve passingwe wish convey hopes wounded incident experience quick full recoveries also regret inconvenience experienced thousands travelers well administration employees los angeles airportthe ciancia family said would continue love care paulwe support difficult times ahead mean minimize grief distress experienced many families hope public understand difficult time family family saidwhat nextif convicted ciancia could face death penalty life prison without parole us attorney general would decide whether pursue death sentencetsa administrator john pistole said shooting prompted review security protocol partner agenciesmccaul said better coordination local law enforcement could improve security checkpointsbut congressman acknowledged difficult stop types attacksit almost like open shopping mall saidopinion nt arm tsa'"
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "source": [
    "# TODO: some words are not properly split; maybe beginning and ending of sentences?\n",
    "cleaned_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'sos an injured officer says he was shot while trying to help an elderly man move to safetylapd provides timeline for welfare check at suspect s homesuspect paul ciancia is in critical condition and could face the death penaltypolice responded to family concern arrived at ciancia s apartment shortly after he left eos'"
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "highlights[0] = \"sos \" + highlights[0] + \" eos\"\n",
    "highlights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tokenizer = Tokenizer(num_words = len(set(cleaned_text[0].split()))+1)\n",
    "X_tokenizer.fit_on_texts(cleaned_text[0].split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "OrderedDict([('weekend', 1),\n             ('intense', 1),\n             ('investigation', 3),\n             ('authorities', 2),\n             ('piecing', 1),\n             ('together', 1),\n             ('details', 1),\n             ('friday', 6),\n             ('fatal', 1),\n             ('shooting', 8),\n             ('los', 5),\n             ('angeles', 6),\n             ('international', 3),\n             ('airport', 8),\n             ('including', 2),\n             ('suspect', 3),\n             ('behavior', 1),\n             ('earlier', 2),\n             ('week', 1),\n             ('warning', 1),\n             ('family', 12),\n             ('may', 2),\n             ('come', 1),\n             ('minutes', 4),\n             ('lateofficers', 1),\n             ('sent', 1),\n             ('check', 2),\n             ('paul', 2),\n             ('ciancia', 20),\n             ('welfare', 1),\n             ('arrived', 4),\n             ('apartment', 3),\n             ('less', 1),\n             ('hour', 1),\n             ('started', 1),\n             ('police', 11),\n             ('said', 19),\n             ('mondayhere', 1),\n             ('rundown', 1),\n             ('get', 1),\n             ('speedthe', 1),\n             ('suspectciancia', 1),\n             ('charged', 1),\n             ('murder', 1),\n             ('federal', 1),\n             ('officer', 4),\n             ('commission', 1),\n             ('violence', 1),\n             ('airporthe', 1),\n             ('shot', 6),\n             ('officers', 7),\n             ('critical', 1),\n             ('condition', 3),\n             ('ronald', 1),\n             ('reagan', 1),\n             ('ucla', 1),\n             ('medical', 1),\n             ('center', 1),\n             ('sundaya', 1),\n             ('source', 3),\n             ('unable', 1),\n             ('speak', 1),\n             ('investigatorsclues', 1),\n             ('motiveattorney', 1),\n             ('general', 2),\n             ('eric', 1),\n             ('holder', 1),\n             ('monday', 6),\n             ('necessary', 1),\n             ('uncover', 1),\n             ('motive', 1),\n             ('attackbut', 1),\n             ('note', 1),\n             ('found', 1),\n             ('indicated', 1),\n             ('wanted', 1),\n             ('kill', 1),\n             ('transportation', 2),\n             ('security', 8),\n             ('administration', 3),\n             ('employees', 2),\n             ('instill', 1),\n             ('fear', 1),\n             ('called', 3),\n             ('agents', 1),\n             ('traitorous', 1),\n             ('minds', 1),\n             ('fbi', 3),\n             ('special', 1),\n             ('agent', 1),\n             ('charge', 1),\n             ('david', 1),\n             ('bowdich', 1),\n             ('saidaccording', 1),\n             ('someone', 1),\n             ('knew', 2),\n             ('three', 1),\n             ('roommates', 1),\n             ('well', 2),\n             ('began', 2),\n             ('asking', 3),\n             ('ride', 2),\n             ('days', 2),\n             ('claimed', 1),\n             ('needed', 3),\n             ('fly', 1),\n             ('new', 3),\n             ('jersey', 2),\n             ('help', 1),\n             ('sick', 1),\n             ('father', 2),\n             ('never', 1),\n             ('day', 1),\n             ('leave', 1),\n             ('saidon', 1),\n             ('burst', 1),\n             ('roommate', 3),\n             ('room', 1),\n             ('demanded', 1),\n             ('immediately', 2),\n             ('spoke', 2),\n             ('cnn', 3),\n             ('anonymitythe', 1),\n             ('obliged', 1),\n             ('investigators', 1),\n             ('nt', 3),\n             ('think', 2),\n             ('idea', 1),\n             ('plansthe', 1),\n             ('nearsavearound', 1),\n             ('time', 2),\n             ('sending', 1),\n             ('text', 1),\n             ('messages', 2),\n             ('members', 1),\n             ('pennsville', 2),\n             ('jerseyone', 1),\n             ('suggested', 1),\n             ('something', 2),\n             ('bad', 1),\n             ('would', 3),\n             ('happenalthough', 1),\n             ('known', 1),\n             ('history', 1),\n             ('mental', 1),\n             ('illness', 1),\n             ('texts', 1),\n             ('unhappy', 1),\n             ('alarming', 1),\n             ('enough', 1),\n             ('decided', 1),\n             ('call', 2),\n             ('policei', 1),\n             ('felt', 1),\n             ('pretty', 1),\n             ('serious', 1),\n             ('sounded', 1),\n             ('california', 1),\n             ('thinking', 1),\n             ('harming', 1),\n             ('obviously', 1),\n             ('make', 1),\n             ('phone', 1),\n             ('lapd', 2),\n             ('chief', 3),\n             ('allen', 1),\n             ('cummings', 1),\n             ('told', 5),\n             ('jake', 1),\n             ('tapper', 1),\n             ('mondaycummings', 1),\n             ('lieutenant', 1),\n             ('department', 2),\n             ('middle', 1),\n             ('responding', 1),\n             ('laxat', 1),\n             ('point', 1),\n             ('connecting', 1),\n             ('dots', 1),\n             ('later', 2),\n             ('reporter', 1),\n             ('comment', 1),\n             ('shootinglos', 1),\n             ('cmdr', 1),\n             ('andy', 1),\n             ('smith', 1),\n             ('says', 1),\n             ('first', 2),\n             ('six', 1),\n             ('according', 5),\n             ('smithciancia', 1),\n             ('already', 1),\n             ('gonethe', 1),\n             ('timeline', 1),\n             ('provided', 1),\n             ('differed', 1),\n             ('offered', 1),\n             ('rep', 1),\n             ('michael', 1),\n             ('mccaul', 1),\n             ('rtexas', 1),\n             ('chairman', 1),\n             ('house', 1),\n             ('homeland', 1),\n             ('committee', 1),\n             ('left', 2),\n             ('airportaccording', 2),\n             ('account', 1),\n             ('clear', 1),\n             ('airportthe', 2),\n             ('attackabout', 1),\n             ('walked', 1),\n             ('checkpoint', 1),\n             ('terminal', 1),\n             ('pulled', 1),\n             ('caliber', 1),\n             ('assault', 1),\n             ('rifle', 1),\n             ('bag', 1),\n             ('tsa', 6),\n             ('gerardo', 1),\n             ('hernandez', 4),\n             ('pointblank', 1),\n             ('range', 1),\n             ('court', 1),\n             ('document', 1),\n             ('filed', 1),\n             ('agentciancia', 1),\n             ('went', 2),\n             ('escalator', 1),\n             ('returned', 1),\n             ('shoot', 1),\n             ('apparently', 1),\n             ('seeing', 1),\n             ('movehe', 1),\n             ('continued', 1),\n             ('walking', 1),\n             ('witnesses', 1),\n             ('person', 2),\n             ('tsai', 1),\n             ('shook', 1),\n             ('head', 1),\n             ('traveler', 2),\n             ('leon', 1),\n             ('saryan', 1),\n             ('anderson', 1),\n             ('cooper', 1),\n             ('kept', 1),\n             ('goingchaos', 1),\n             ('terror', 1),\n             ('inside', 2),\n             ('lax', 4),\n             ('terminalthe', 1),\n             ('victimshernandez', 1),\n             ('die', 1),\n             ('line', 1),\n             ('duty', 2),\n             ('since', 1),\n             ('agency', 1),\n             ('created', 1),\n             ('inhe', 1),\n             ('took', 1),\n             ('pride', 1),\n             ('american', 1),\n             ('public', 2),\n             ('mission', 1),\n             ('wife', 1),\n             ('ana', 1),\n             ('hernandezthe', 1),\n             ('couple', 1),\n             ('married', 1),\n             ('two', 2),\n             ('childrentwo', 1),\n             ('james', 1),\n             ('speer', 1),\n             ('tony', 1),\n             ('grigsby', 1),\n             ('wounded', 2),\n             ('released', 1),\n             ('hospitalgrigsby', 1),\n             ('foot', 1),\n             ('reporters', 1),\n             ('injured', 1),\n             ('helping', 1),\n             ('elderly', 1),\n             ('man', 2),\n             ('move', 1),\n             ('safe', 1),\n             ('areai', 1),\n             ('turned', 1),\n             ('around', 1),\n             ('gunman', 1),\n             ('twicea', 1),\n             ('leg', 1),\n             ('brian', 1),\n             ('ludmer', 1),\n             ('lake', 1),\n             ('forest', 1),\n             ('illinois', 1),\n             ('fair', 1),\n             ('sundaythe', 1),\n             ('responsetsa', 1),\n             ('unarmed', 1),\n             ('eventually', 1),\n             ('multiple', 1),\n             ('times', 2),\n             ('chest', 1),\n             ('also', 2),\n             ('striking', 1),\n             ('face', 2),\n             ('neckairport', 1),\n             ('patrick', 1),\n             ('gannon', 2),\n             ('seconds', 1),\n             ('behind', 2),\n             ('praised', 1),\n             ('response', 1),\n             ('even', 1),\n             ('though', 1),\n             ('acknowledged', 2),\n             ('moved', 2),\n             ('away', 1),\n             ('positions', 1),\n             ('checkpoints', 1),\n             ('past', 1),\n             ('yearthe', 1),\n             ('threat', 2),\n             ('exist', 1),\n             ('podium', 1),\n             ('exists', 1),\n             ('curbline', 1),\n             ('people', 1),\n             ('stationed', 1),\n             ('throughout', 1),\n             ('airportholder', 1),\n             ('include', 1),\n             ('review', 2),\n             ('measures', 1),\n             ('airportsthe', 1),\n             ('responsibility', 1),\n             ('protecting', 1),\n             ('function', 1),\n             ('need', 1),\n             ('certainly', 1),\n             ('examine', 1),\n             ('given', 1),\n             ('happened', 1),\n             ('saidtravel', 1),\n             ('delaysthe', 1),\n             ('incident', 4),\n             ('forced', 1),\n             ('shut', 1),\n             ('parts', 1),\n             ('evacuate', 1),\n             ('travelers', 2),\n             ('put', 1),\n             ('temporary', 1),\n             ('hold', 1),\n             ('departures', 1),\n             ('landingsmore', 1),\n             ('airline', 2),\n             ('passengers', 2),\n             ('affected', 2),\n             ('result', 1),\n             ('cancellations', 2),\n             ('delays', 2),\n             ('diversions', 1),\n             ('airports', 1),\n             ('one', 1),\n             ('jetblue', 1),\n             ('temporarily', 1),\n             ('operations', 1),\n             ('long', 1),\n             ('beach', 1),\n             ('airporton', 1),\n             ('saturday', 1),\n             ('additional', 2),\n             ('flights', 3),\n             ('canceled', 2),\n             ('involving', 1),\n             ('flightaware', 2),\n             ('flight', 1),\n             ('tracking', 1),\n             ('website', 1),\n             ('airlines', 1),\n             ('morning', 1),\n             ('saturdayan', 1),\n             ('delayed', 1),\n             ('saidsome', 1),\n             ('caused', 1),\n             ('problems', 1),\n             ('howeverthe', 1),\n             ('operating', 1),\n             ('normally', 1),\n             ('morningsuspect', 1),\n             ('respondsciancia', 1),\n             ('statement', 1),\n             ('read', 1),\n             ('afternoon', 1),\n             ('attorney', 2),\n             ('john', 2),\n             ('jordan', 1),\n             ('shocked', 1),\n             ('numbed', 1),\n             ('tragic', 1),\n             ('events', 1),\n             ('last', 1),\n             ('fridayit', 1),\n             ('important', 1),\n             ('us', 2),\n             ('express', 1),\n             ('deep', 1),\n             ('sincere', 1),\n             ('sympathy', 1),\n             ('lrb', 1),\n             ('rrb', 1),\n             ('accounts', 1),\n             ('exemplary', 1),\n             ('member', 1),\n             ('law', 2),\n             ('enforcement', 2),\n             ('community', 1),\n             ('good', 1),\n             ('hearts', 1),\n             ('go', 1),\n             ('many', 2),\n             ('others', 1),\n             ('grieve', 1),\n             ('passingwe', 1),\n             ('wish', 1),\n             ('convey', 1),\n             ('hopes', 1),\n             ('experience', 1),\n             ('quick', 1),\n             ('full', 1),\n             ('recoveries', 1),\n             ('regret', 1),\n             ('inconvenience', 1),\n             ('experienced', 2),\n             ('thousands', 1),\n             ('continue', 1),\n             ('love', 1),\n             ('care', 1),\n             ('paulwe', 1),\n             ('support', 1),\n             ('difficult', 3),\n             ('ahead', 1),\n             ('mean', 1),\n             ('minimize', 1),\n             ('grief', 1),\n             ('distress', 1),\n             ('families', 1),\n             ('hope', 1),\n             ('understand', 1),\n             ('saidwhat', 1),\n             ('nextif', 1),\n             ('convicted', 1),\n             ('could', 2),\n             ('death', 2),\n             ('penalty', 1),\n             ('life', 1),\n             ('prison', 1),\n             ('without', 1),\n             ('parole', 1),\n             ('decide', 1),\n             ('whether', 1),\n             ('pursue', 1),\n             ('sentencetsa', 1),\n             ('administrator', 1),\n             ('pistole', 1),\n             ('prompted', 1),\n             ('protocol', 1),\n             ('partner', 1),\n             ('agenciesmccaul', 1),\n             ('better', 1),\n             ('coordination', 1),\n             ('local', 1),\n             ('improve', 1),\n             ('checkpointsbut', 1),\n             ('congressman', 1),\n             ('stop', 1),\n             ('types', 1),\n             ('attacksit', 1),\n             ('almost', 1),\n             ('like', 1),\n             ('open', 1),\n             ('shopping', 1),\n             ('mall', 1),\n             ('saidopinion', 1),\n             ('arm', 1)])"
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "X_tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: why 90? this will probably fuck up the embedding layer because we only have 51 words in the abstract and the embedding thinks our vocabulary has size 90\n",
    "Y_tokenizer = Tokenizer(num_words = len(set(highlights[0].split())) + 1)\n",
    "Y_tokenizer.fit_on_texts(highlights[0].split())\n",
    "Y_voc = Y_tokenizer.num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "OrderedDict([('sos', 1),\n             ('an', 2),\n             ('injured', 1),\n             ('officer', 1),\n             ('says', 1),\n             ('he', 2),\n             ('was', 1),\n             ('shot', 1),\n             ('while', 1),\n             ('trying', 1),\n             ('to', 3),\n             ('help', 1),\n             ('elderly', 1),\n             ('man', 1),\n             ('move', 1),\n             ('safetylapd', 1),\n             ('provides', 1),\n             ('timeline', 1),\n             ('for', 1),\n             ('welfare', 1),\n             ('check', 1),\n             ('at', 2),\n             ('suspect', 1),\n             ('s', 2),\n             ('homesuspect', 1),\n             ('paul', 1),\n             ('ciancia', 2),\n             ('is', 1),\n             ('in', 1),\n             ('critical', 1),\n             ('condition', 1),\n             ('and', 1),\n             ('could', 1),\n             ('face', 1),\n             ('the', 1),\n             ('death', 1),\n             ('penaltypolice', 1),\n             ('responded', 1),\n             ('family', 1),\n             ('concern', 1),\n             ('arrived', 1),\n             ('apartment', 1),\n             ('shortly', 1),\n             ('after', 1),\n             ('left', 1),\n             ('eos', 1)])"
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "source": [
    "Y_tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_idx(data: list) -> dict:\n",
    "    \"\"\"\n",
    "    Function that maps the data and return a dictionary of words corresponding to their index\n",
    "    it gets a list\n",
    "    return:\n",
    "        dict 1 idx to word\n",
    "        dict 2 word to idx\n",
    "    \"\"\"\n",
    "    total_letters = [letters for sublist in data for subsublist in sublist for letters in subsublist]\n",
    "    unique_letters =set(total_letters)\n",
    "    total_words = [word.replace(',','') for sublist in data for subsublist in sublist for word in subsublist.split()]\n",
    "    unique_words =list(set(total_words))\n",
    "\n",
    "    w_2_i = {unique_words[i]:i for i in range(len(unique_words))}\n",
    "    i_2_w= {i: unique_words[i] for i in range(len(unique_words))}\n",
    "    print(w_2_i)\n",
    "    input()\n",
    "    return (w_2_i, i_2_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= X_tokenizer.texts_to_sequences(cleaned_text[0].split()) \n",
    "y_train  = Y_tokenizer.texts_to_sequences(highlights[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "735"
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "53"
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "491"
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": [
    "X_tokenizer.num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "47"
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "Y_tokenizer.num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[[109],\n [110],\n [23],\n [42],\n [111],\n [112],\n [113],\n [9],\n [114],\n [5],\n [14],\n [10],\n [24],\n [6],\n [43],\n [25],\n [115],\n [44],\n [116],\n [117],\n [3],\n [45],\n [118],\n [17],\n [119],\n [120],\n [46],\n [47],\n [1],\n [121],\n [18],\n [26],\n [122],\n [123],\n [5],\n [124],\n [4],\n [2],\n [125],\n [126],\n [127],\n [128],\n [129],\n [14],\n [10],\n [130],\n [131],\n [132],\n [19],\n [133],\n [134],\n [24],\n [135],\n [11],\n [8],\n [9],\n [136],\n [27],\n [137],\n [138],\n [139],\n [140],\n [141],\n [142],\n [28],\n [2],\n [1],\n [143],\n [144],\n [145],\n [146],\n [48],\n [147],\n [148],\n [2],\n [12],\n [23],\n [149],\n [150],\n [151],\n [152],\n [153],\n [154],\n [1],\n [155],\n [156],\n [157],\n [49],\n [7],\n [29],\n [50],\n [158],\n [159],\n [25],\n [30],\n [160],\n [161],\n [162],\n [31],\n [163],\n [164],\n [165],\n [166],\n [167],\n [168],\n [169],\n [51],\n [1],\n [170],\n [171],\n [52],\n [1],\n [53],\n [32],\n [54],\n [6],\n [55],\n [5],\n [172],\n [33],\n [173],\n [34],\n [56],\n [174],\n [175],\n [57],\n [176],\n [2],\n [177],\n [33],\n [178],\n [28],\n [179],\n [9],\n [1],\n [180],\n [35],\n [181],\n [182],\n [54],\n [6],\n [58],\n [2],\n [28],\n [59],\n [36],\n [27],\n [183],\n [35],\n [184],\n [185],\n [37],\n [60],\n [35],\n [186],\n [1],\n [187],\n [188],\n [61],\n [1],\n [189],\n [190],\n [62],\n [3],\n [191],\n [63],\n [34],\n [192],\n [193],\n [64],\n [194],\n [38],\n [195],\n [1],\n [196],\n [197],\n [198],\n [199],\n [2],\n [200],\n [201],\n [62],\n [202],\n [203],\n [1],\n [57],\n [204],\n [65],\n [205],\n [206],\n [207],\n [208],\n [209],\n [47],\n [1],\n [210],\n [211],\n [212],\n [213],\n [51],\n [33],\n [214],\n [215],\n [65],\n [66],\n [63],\n [4],\n [39],\n [216],\n [217],\n [15],\n [36],\n [218],\n [219],\n [220],\n [59],\n [221],\n [15],\n [67],\n [222],\n [223],\n [5],\n [224],\n [225],\n [37],\n [226],\n [227],\n [2],\n [68],\n [228],\n [30],\n [4],\n [39],\n [32],\n [229],\n [230],\n [10],\n [4],\n [67],\n [231],\n [232],\n [233],\n [234],\n [4],\n [69],\n [30],\n [46],\n [1],\n [8],\n [18],\n [26],\n [235],\n [17],\n [68],\n [16],\n [236],\n [237],\n [238],\n [239],\n [240],\n [12],\n [4],\n [241],\n [242],\n [44],\n [243],\n [244],\n [245],\n [246],\n [247],\n [248],\n [249],\n [7],\n [250],\n [2],\n [4],\n [18],\n [1],\n [26],\n [17],\n [25],\n [70],\n [71],\n [66],\n [251],\n [18],\n [17],\n [5],\n [53],\n [16],\n [4],\n [58],\n [252],\n [1],\n [70],\n [72],\n [253],\n [9],\n [1],\n [254],\n [49],\n [7],\n [29],\n [255],\n [256],\n [257],\n [258],\n [259],\n [260],\n [261],\n [11],\n [13],\n [19],\n [262],\n [20],\n [263],\n [264],\n [16],\n [265],\n [266],\n [267],\n [31],\n [268],\n [73],\n [269],\n [270],\n [271],\n [20],\n [272],\n [273],\n [274],\n [275],\n [276],\n [5],\n [277],\n [2],\n [73],\n [74],\n [74],\n [32],\n [278],\n [279],\n [280],\n [75],\n [281],\n [282],\n [15],\n [36],\n [283],\n [284],\n [285],\n [286],\n [287],\n [76],\n [21],\n [288],\n [289],\n [69],\n [13],\n [19],\n [290],\n [291],\n [77],\n [292],\n [293],\n [294],\n [295],\n [296],\n [297],\n [77],\n [298],\n [78],\n [13],\n [299],\n [2],\n [300],\n [301],\n [302],\n [303],\n [304],\n [79],\n [305],\n [13],\n [8],\n [306],\n [307],\n [308],\n [309],\n [80],\n [310],\n [311],\n [11],\n [312],\n [15],\n [313],\n [12],\n [314],\n [315],\n [316],\n [81],\n [317],\n [318],\n [319],\n [320],\n [321],\n [322],\n [2],\n [11],\n [323],\n [75],\n [11],\n [324],\n [325],\n [326],\n [327],\n [328],\n [329],\n [330],\n [27],\n [331],\n [4],\n [332],\n [8],\n [333],\n [6],\n [4],\n [8],\n [334],\n [11],\n [1],\n [335],\n [82],\n [336],\n [83],\n [337],\n [84],\n [338],\n [4],\n [39],\n [339],\n [85],\n [2],\n [31],\n [15],\n [8],\n [340],\n [86],\n [1],\n [341],\n [342],\n [343],\n [344],\n [87],\n [88],\n [8],\n [345],\n [346],\n [76],\n [347],\n [348],\n [349],\n [89],\n [6],\n [350],\n [86],\n [7],\n [351],\n [89],\n [352],\n [353],\n [85],\n [2],\n [354],\n [355],\n [356],\n [357],\n [2],\n [12],\n [23],\n [358],\n [90],\n [7],\n [359],\n [21],\n [360],\n [361],\n [362],\n [6],\n [7],\n [13],\n [363],\n [64],\n [60],\n [364],\n [365],\n [366],\n [367],\n [368],\n [14],\n [10],\n [369],\n [370],\n [22],\n [371],\n [42],\n [372],\n [373],\n [6],\n [374],\n [91],\n [375],\n [376],\n [377],\n [378],\n [379],\n [92],\n [93],\n [94],\n [22],\n [9],\n [380],\n [95],\n [96],\n [381],\n [382],\n [16],\n [21],\n [383],\n [92],\n [384],\n [385],\n [88],\n [386],\n [387],\n [388],\n [389],\n [390],\n [97],\n [40],\n [94],\n [43],\n [98],\n [391],\n [93],\n [16],\n [14],\n [10],\n [24],\n [71],\n [99],\n [392],\n [393],\n [394],\n [395],\n [98],\n [40],\n [21],\n [22],\n [9],\n [396],\n [397],\n [97],\n [40],\n [398],\n [79],\n [55],\n [99],\n [399],\n [95],\n [96],\n [45],\n [400],\n [401],\n [5],\n [402],\n [6],\n [403],\n [404],\n [12],\n [405],\n [3],\n [406],\n [3],\n [407],\n [408],\n [12],\n [409],\n [100],\n [101],\n [410],\n [34],\n [56],\n [2],\n [411],\n [412],\n [413],\n [414],\n [415],\n [416],\n [417],\n [102],\n [3],\n [418],\n [419],\n [420],\n [421],\n [20],\n [3],\n [1],\n [3],\n [2],\n [422],\n [423],\n [424],\n [19],\n [20],\n [425],\n [426],\n [103],\n [104],\n [427],\n [428],\n [3],\n [81],\n [429],\n [430],\n [3],\n [105],\n [431],\n [432],\n [433],\n [434],\n [435],\n [436],\n [80],\n [22],\n [437],\n [438],\n [439],\n [440],\n [83],\n [441],\n [442],\n [106],\n [443],\n [91],\n [52],\n [29],\n [50],\n [14],\n [10],\n [72],\n [1],\n [3],\n [2],\n [38],\n [444],\n [445],\n [446],\n [447],\n [448],\n [41],\n [82],\n [449],\n [450],\n [451],\n [452],\n [453],\n [106],\n [105],\n [454],\n [455],\n [78],\n [456],\n [41],\n [61],\n [3],\n [3],\n [457],\n [458],\n [459],\n [1],\n [107],\n [84],\n [108],\n [460],\n [461],\n [462],\n [463],\n [464],\n [102],\n [100],\n [48],\n [38],\n [465],\n [466],\n [467],\n [108],\n [468],\n [469],\n [101],\n [470],\n [2],\n [5],\n [471],\n [90],\n [7],\n [472],\n [473],\n [474],\n [2],\n [475],\n [476],\n [477],\n [103],\n [104],\n [107],\n [478],\n [7],\n [479],\n [480],\n [87],\n [41],\n [481],\n [482],\n [483],\n [484],\n [485],\n [486],\n [487],\n [488],\n [489],\n [37],\n [490],\n [13]]"
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[[7],\n [2],\n [8],\n [9],\n [10],\n [3],\n [11],\n [12],\n [13],\n [14],\n [1],\n [15],\n [2],\n [16],\n [17],\n [18],\n [1],\n [19],\n [20],\n [21],\n [22],\n [23],\n [24],\n [4],\n [25],\n [5],\n [26],\n [27],\n [6],\n [28],\n [29],\n [30],\n [31],\n [32],\n [33],\n [34],\n [35],\n [36],\n [37],\n [38],\n [1],\n [39],\n [40],\n [41],\n [4],\n [6],\n [5],\n [42],\n [43],\n [44],\n [3],\n [45],\n [46]]"
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_voc = X_tokenizer.num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "str"
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "source": [
    "type(highlights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y_train)\n",
    "x = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(53, 1)"
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(735, 1)"
     },
     "metadata": {},
     "execution_count": 118
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(1,-1)\n",
    "y = y.reshape(1,-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1, 735)"
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1, 53)"
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[109, 110,  23,  42, 111, 112, 113,   9, 114,   5,  14,  10,  24,\n          6,  43,  25, 115,  44, 116, 117,   3,  45, 118,  17, 119, 120,\n         46,  47,   1, 121,  18,  26, 122, 123,   5, 124,   4,   2, 125,\n        126, 127, 128, 129,  14,  10, 130, 131, 132,  19, 133, 134,  24,\n        135,  11,   8,   9, 136,  27, 137, 138, 139, 140, 141, 142,  28,\n          2,   1, 143, 144, 145, 146,  48, 147, 148,   2,  12,  23, 149,\n        150, 151, 152, 153, 154,   1, 155, 156, 157,  49,   7,  29,  50,\n        158, 159,  25,  30, 160, 161, 162,  31, 163, 164, 165, 166, 167,\n        168, 169,  51,   1, 170, 171,  52,   1,  53,  32,  54,   6,  55,\n          5, 172,  33, 173,  34,  56, 174, 175,  57, 176,   2, 177,  33,\n        178,  28, 179,   9,   1, 180,  35, 181, 182,  54,   6,  58,   2,\n         28,  59,  36,  27, 183,  35, 184, 185,  37,  60,  35, 186,   1,\n        187, 188,  61,   1, 189, 190,  62,   3, 191,  63,  34, 192, 193,\n         64, 194,  38, 195,   1, 196, 197, 198, 199,   2, 200, 201,  62,\n        202, 203,   1,  57, 204,  65, 205, 206, 207, 208, 209,  47,   1,\n        210, 211, 212, 213,  51,  33, 214, 215,  65,  66,  63,   4,  39,\n        216, 217,  15,  36, 218, 219, 220,  59, 221,  15,  67, 222, 223,\n          5, 224, 225,  37, 226, 227,   2,  68, 228,  30,   4,  39,  32,\n        229, 230,  10,   4,  67, 231, 232, 233, 234,   4,  69,  30,  46,\n          1,   8,  18,  26, 235,  17,  68,  16, 236, 237, 238, 239, 240,\n         12,   4, 241, 242,  44, 243, 244, 245, 246, 247, 248, 249,   7,\n        250,   2,   4,  18,   1,  26,  17,  25,  70,  71,  66, 251,  18,\n         17,   5,  53,  16,   4,  58, 252,   1,  70,  72, 253,   9,   1,\n        254,  49,   7,  29, 255, 256, 257, 258, 259, 260, 261,  11,  13,\n         19, 262,  20, 263, 264,  16, 265, 266, 267,  31, 268,  73, 269,\n        270, 271,  20, 272, 273, 274, 275, 276,   5, 277,   2,  73,  74,\n         74,  32, 278, 279, 280,  75, 281, 282,  15,  36, 283, 284, 285,\n        286, 287,  76,  21, 288, 289,  69,  13,  19, 290, 291,  77, 292,\n        293, 294, 295, 296, 297,  77, 298,  78,  13, 299,   2, 300, 301,\n        302, 303, 304,  79, 305,  13,   8, 306, 307, 308, 309,  80, 310,\n        311,  11, 312,  15, 313,  12, 314, 315, 316,  81, 317, 318, 319,\n        320, 321, 322,   2,  11, 323,  75,  11, 324, 325, 326, 327, 328,\n        329, 330,  27, 331,   4, 332,   8, 333,   6,   4,   8, 334,  11,\n          1, 335,  82, 336,  83, 337,  84, 338,   4,  39, 339,  85,   2,\n         31,  15,   8, 340,  86,   1, 341, 342, 343, 344,  87,  88,   8,\n        345, 346,  76, 347, 348, 349,  89,   6, 350,  86,   7, 351,  89,\n        352, 353,  85,   2, 354, 355, 356, 357,   2,  12,  23, 358,  90,\n          7, 359,  21, 360, 361, 362,   6,   7,  13, 363,  64,  60, 364,\n        365, 366, 367, 368,  14,  10, 369, 370,  22, 371,  42, 372, 373,\n          6, 374,  91, 375, 376, 377, 378, 379,  92,  93,  94,  22,   9,\n        380,  95,  96, 381, 382,  16,  21, 383,  92, 384, 385,  88, 386,\n        387, 388, 389, 390,  97,  40,  94,  43,  98, 391,  93,  16,  14,\n         10,  24,  71,  99, 392, 393, 394, 395,  98,  40,  21,  22,   9,\n        396, 397,  97,  40, 398,  79,  55,  99, 399,  95,  96,  45, 400,\n        401,   5, 402,   6, 403, 404,  12, 405,   3, 406,   3, 407, 408,\n         12, 409, 100, 101, 410,  34,  56,   2, 411, 412, 413, 414, 415,\n        416, 417, 102,   3, 418, 419, 420, 421,  20,   3,   1,   3,   2,\n        422, 423, 424,  19,  20, 425, 426, 103, 104, 427, 428,   3,  81,\n        429, 430,   3, 105, 431, 432, 433, 434, 435, 436,  80,  22, 437,\n        438, 439, 440,  83, 441, 442, 106, 443,  91,  52,  29,  50,  14,\n         10,  72,   1,   3,   2,  38, 444, 445, 446, 447, 448,  41,  82,\n        449, 450, 451, 452, 453, 106, 105, 454, 455,  78, 456,  41,  61,\n          3,   3, 457, 458, 459,   1, 107,  84, 108, 460, 461, 462, 463,\n        464, 102, 100,  48,  38, 465, 466, 467, 108, 468, 469, 101, 470,\n          2,   5, 471,  90,   7, 472, 473, 474,   2, 475, 476, 477, 103,\n        104, 107, 478,   7, 479, 480,  87,  41, 481, 482, 483, 484, 485,\n        486, 487, 488, 489,  37, 490,  13]])"
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ 7,  2,  8,  9, 10,  3, 11, 12, 13, 14,  1, 15,  2, 16, 17, 18,\n         1, 19, 20, 21, 22, 23, 24,  4, 25,  5, 26, 27,  6, 28, 29, 30,\n        31, 32, 33, 34, 35, 36, 37, 38,  1, 39, 40, 41,  4,  6,  5, 42,\n        43, 44,  3, 45, 46]])"
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "47"
     },
     "metadata": {},
     "execution_count": 124
    }
   ],
   "source": [
    "Y_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "============================================\nTotal params: 219,347\nTrainable params: 219,347\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/200\n1/1 [==============================] - 8s 8s/step - loss: 3.8499 - accuracy: 0.0000e+00\nEpoch 2/200\n1/1 [==============================] - 1s 982ms/step - loss: 3.8366 - accuracy: 0.0962\nEpoch 3/200\n1/1 [==============================] - 1s 949ms/step - loss: 3.8238 - accuracy: 0.1154\nEpoch 4/200\n1/1 [==============================] - 1s 981ms/step - loss: 3.8062 - accuracy: 0.0962\nEpoch 5/200\n1/1 [==============================] - 1s 937ms/step - loss: 3.7255 - accuracy: 0.0577\nEpoch 6/200\n1/1 [==============================] - 1s 944ms/step - loss: 3.6189 - accuracy: 0.0577\nEpoch 7/200\n1/1 [==============================] - 1s 959ms/step - loss: 3.4954 - accuracy: 0.0769\nEpoch 8/200\n1/1 [==============================] - 1s 926ms/step - loss: 3.3753 - accuracy: 0.0769\nEpoch 9/200\n1/1 [==============================] - 1s 951ms/step - loss: 3.3033 - accuracy: 0.0577\nEpoch 10/200\n1/1 [==============================] - 1s 953ms/step - loss: 3.2791 - accuracy: 0.1154\nEpoch 11/200\n1/1 [==============================] - 1s 945ms/step - loss: 3.1660 - accuracy: 0.0962\nEpoch 12/200\n1/1 [==============================] - 1s 944ms/step - loss: 3.1056 - accuracy: 0.1538\nEpoch 13/200\n1/1 [==============================] - 1s 946ms/step - loss: 3.0511 - accuracy: 0.0962\nEpoch 14/200\n1/1 [==============================] - 1s 1s/step - loss: 3.0037 - accuracy: 0.1538\nEpoch 15/200\n1/1 [==============================] - 1s 964ms/step - loss: 2.9813 - accuracy: 0.0769\nEpoch 16/200\n1/1 [==============================] - 1s 938ms/step - loss: 2.9430 - accuracy: 0.1731\nEpoch 17/200\n1/1 [==============================] - 1s 953ms/step - loss: 2.8743 - accuracy: 0.1538\nEpoch 18/200\n1/1 [==============================] - 1s 945ms/step - loss: 2.8511 - accuracy: 0.2115\nEpoch 19/200\n1/1 [==============================] - 1s 958ms/step - loss: 2.7888 - accuracy: 0.1538\nEpoch 20/200\n1/1 [==============================] - 1s 961ms/step - loss: 2.7486 - accuracy: 0.1923\nEpoch 21/200\n1/1 [==============================] - 1s 962ms/step - loss: 2.7088 - accuracy: 0.1923\nEpoch 22/200\n1/1 [==============================] - 1s 963ms/step - loss: 2.6797 - accuracy: 0.1923\nEpoch 23/200\n1/1 [==============================] - 1s 957ms/step - loss: 2.7140 - accuracy: 0.1538\nEpoch 24/200\n1/1 [==============================] - 1s 1s/step - loss: 2.7399 - accuracy: 0.1923\nEpoch 25/200\n1/1 [==============================] - 1s 957ms/step - loss: 2.5846 - accuracy: 0.2885\nEpoch 26/200\n1/1 [==============================] - 1s 961ms/step - loss: 2.5254 - accuracy: 0.3269\nEpoch 27/200\n1/1 [==============================] - 1s 954ms/step - loss: 2.4984 - accuracy: 0.2885\nEpoch 28/200\n1/1 [==============================] - 1s 961ms/step - loss: 2.4683 - accuracy: 0.3462\nEpoch 29/200\n1/1 [==============================] - 1s 972ms/step - loss: 2.4247 - accuracy: 0.3846\nEpoch 30/200\n1/1 [==============================] - 1s 962ms/step - loss: 2.4433 - accuracy: 0.2308\nEpoch 31/200\n1/1 [==============================] - 1s 961ms/step - loss: 2.5338 - accuracy: 0.2308\nEpoch 32/200\n1/1 [==============================] - 1s 968ms/step - loss: 2.4029 - accuracy: 0.2885\nEpoch 33/200\n1/1 [==============================] - 1s 934ms/step - loss: 2.3557 - accuracy: 0.3462\nEpoch 34/200\n1/1 [==============================] - 1s 923ms/step - loss: 2.2962 - accuracy: 0.3462\nEpoch 35/200\n1/1 [==============================] - 1s 920ms/step - loss: 2.2455 - accuracy: 0.4231\nEpoch 36/200\n1/1 [==============================] - 1s 940ms/step - loss: 2.2349 - accuracy: 0.3654\nEpoch 37/200\n1/1 [==============================] - 1s 940ms/step - loss: 2.2881 - accuracy: 0.3654\nEpoch 38/200\n1/1 [==============================] - 1s 940ms/step - loss: 2.2772 - accuracy: 0.2500\nEpoch 39/200\n1/1 [==============================] - 1s 949ms/step - loss: 2.2773 - accuracy: 0.2500\nEpoch 40/200\n1/1 [==============================] - 1s 1s/step - loss: 2.1943 - accuracy: 0.3462\nEpoch 41/200\n1/1 [==============================] - 1s 996ms/step - loss: 2.1919 - accuracy: 0.3846\nEpoch 42/200\n1/1 [==============================] - 1s 948ms/step - loss: 2.1830 - accuracy: 0.2885\nEpoch 43/200\n1/1 [==============================] - 1s 934ms/step - loss: 2.1105 - accuracy: 0.3846\nEpoch 44/200\n1/1 [==============================] - 1s 1s/step - loss: 2.0867 - accuracy: 0.4231\nEpoch 45/200\n1/1 [==============================] - 1s 960ms/step - loss: 2.1329 - accuracy: 0.3269\nEpoch 46/200\n1/1 [==============================] - 1s 920ms/step - loss: 2.0651 - accuracy: 0.4615\nEpoch 47/200\n1/1 [==============================] - 1s 970ms/step - loss: 2.0105 - accuracy: 0.5769\nEpoch 48/200\n1/1 [==============================] - 1s 931ms/step - loss: 1.9885 - accuracy: 0.5192\nEpoch 49/200\n1/1 [==============================] - 1s 943ms/step - loss: 1.9852 - accuracy: 0.4423\nEpoch 50/200\n1/1 [==============================] - 1s 937ms/step - loss: 1.9674 - accuracy: 0.5385\nEpoch 51/200\n1/1 [==============================] - 1s 928ms/step - loss: 2.0309 - accuracy: 0.3269\nEpoch 52/200\n1/1 [==============================] - 1s 922ms/step - loss: 2.1531 - accuracy: 0.1538\nEpoch 53/200\n1/1 [==============================] - 1s 946ms/step - loss: 2.0467 - accuracy: 0.3077\nEpoch 54/200\n1/1 [==============================] - 1s 919ms/step - loss: 1.9116 - accuracy: 0.5000\nEpoch 55/200\n1/1 [==============================] - 1s 937ms/step - loss: 1.8591 - accuracy: 0.5962\nEpoch 56/200\n1/1 [==============================] - 1s 931ms/step - loss: 1.8808 - accuracy: 0.5769\nEpoch 57/200\n1/1 [==============================] - 1s 966ms/step - loss: 1.8689 - accuracy: 0.5192\nEpoch 58/200\n1/1 [==============================] - 1s 1s/step - loss: 1.8489 - accuracy: 0.4808\nEpoch 59/200\n1/1 [==============================] - 1s 955ms/step - loss: 1.8693 - accuracy: 0.4423\nEpoch 60/200\n1/1 [==============================] - 1s 923ms/step - loss: 1.8360 - accuracy: 0.5577\nEpoch 61/200\n1/1 [==============================] - 1s 1s/step - loss: 1.8510 - accuracy: 0.5000\nEpoch 62/200\n1/1 [==============================] - 1s 947ms/step - loss: 1.7629 - accuracy: 0.7308\nEpoch 63/200\n1/1 [==============================] - 1s 944ms/step - loss: 1.7341 - accuracy: 0.6923\nEpoch 64/200\n1/1 [==============================] - 1s 974ms/step - loss: 1.7044 - accuracy: 0.7115\nEpoch 65/200\n1/1 [==============================] - 1s 939ms/step - loss: 1.7087 - accuracy: 0.6923\nEpoch 66/200\n1/1 [==============================] - 1s 931ms/step - loss: 1.6844 - accuracy: 0.6731\nEpoch 67/200\n1/1 [==============================] - 1s 962ms/step - loss: 1.6833 - accuracy: 0.7115\nEpoch 68/200\n1/1 [==============================] - 1s 953ms/step - loss: 1.6511 - accuracy: 0.7500\nEpoch 69/200\n1/1 [==============================] - 1s 967ms/step - loss: 1.6589 - accuracy: 0.6346\nEpoch 70/200\n1/1 [==============================] - 1s 957ms/step - loss: 1.6512 - accuracy: 0.5962\nEpoch 71/200\n1/1 [==============================] - 1s 1s/step - loss: 1.7963 - accuracy: 0.4038\nEpoch 72/200\n1/1 [==============================] - 1s 955ms/step - loss: 1.9699 - accuracy: 0.1346\nEpoch 73/200\n1/1 [==============================] - 1s 978ms/step - loss: 1.8421 - accuracy: 0.2885\nEpoch 74/200\n1/1 [==============================] - 1s 958ms/step - loss: 1.6516 - accuracy: 0.5577\nEpoch 75/200\n1/1 [==============================] - 1s 967ms/step - loss: 1.5839 - accuracy: 0.7500\nEpoch 76/200\n1/1 [==============================] - 1s 968ms/step - loss: 1.5703 - accuracy: 0.8269\nEpoch 77/200\n1/1 [==============================] - 1s 969ms/step - loss: 1.5803 - accuracy: 0.7692\nEpoch 78/200\n1/1 [==============================] - 1s 1s/step - loss: 1.5425 - accuracy: 0.7115\nEpoch 79/200\n1/1 [==============================] - 1s 975ms/step - loss: 1.5328 - accuracy: 0.7692\nEpoch 80/200\n1/1 [==============================] - 1s 1s/step - loss: 1.5149 - accuracy: 0.7308\nEpoch 81/200\n1/1 [==============================] - 1s 958ms/step - loss: 1.5218 - accuracy: 0.7308\nEpoch 82/200\n1/1 [==============================] - 1s 971ms/step - loss: 1.5820 - accuracy: 0.5577\nEpoch 83/200\n1/1 [==============================] - 1s 988ms/step - loss: 1.7699 - accuracy: 0.2308\nEpoch 84/200\n1/1 [==============================] - 1s 966ms/step - loss: 1.6155 - accuracy: 0.5192\nEpoch 85/200\n1/1 [==============================] - 1s 956ms/step - loss: 1.4654 - accuracy: 0.8846\nEpoch 86/200\n1/1 [==============================] - 1s 967ms/step - loss: 1.4476 - accuracy: 0.8654\nEpoch 87/200\n1/1 [==============================] - 1s 960ms/step - loss: 1.4493 - accuracy: 0.8462\nEpoch 88/200\n1/1 [==============================] - 1s 965ms/step - loss: 1.4421 - accuracy: 0.7692\nEpoch 89/200\n1/1 [==============================] - 1s 965ms/step - loss: 1.4514 - accuracy: 0.6346\nEpoch 90/200\n1/1 [==============================] - 1s 984ms/step - loss: 1.4517 - accuracy: 0.7308\nEpoch 91/200\n1/1 [==============================] - 1s 958ms/step - loss: 1.4374 - accuracy: 0.7885\nEpoch 92/200\n1/1 [==============================] - 1s 998ms/step - loss: 1.4386 - accuracy: 0.6346\nEpoch 93/200\n1/1 [==============================] - 1s 986ms/step - loss: 1.4595 - accuracy: 0.6346\nEpoch 94/200\n1/1 [==============================] - 1s 969ms/step - loss: 1.3628 - accuracy: 0.8846\nEpoch 95/200\n1/1 [==============================] - 1s 995ms/step - loss: 1.3795 - accuracy: 0.8654\nEpoch 96/200\n1/1 [==============================] - 1s 973ms/step - loss: 1.3479 - accuracy: 0.8846\nEpoch 97/200\n1/1 [==============================] - 1s 958ms/step - loss: 1.3572 - accuracy: 0.8077\nEpoch 98/200\n1/1 [==============================] - 1s 992ms/step - loss: 1.5374 - accuracy: 0.3654\nEpoch 99/200\n1/1 [==============================] - 1s 979ms/step - loss: 1.6289 - accuracy: 0.2885\nEpoch 100/200\n1/1 [==============================] - 1s 1s/step - loss: 1.4351 - accuracy: 0.5192\nEpoch 101/200\n1/1 [==============================] - 1s 1s/step - loss: 1.3961 - accuracy: 0.6346\nEpoch 102/200\n1/1 [==============================] - 1s 971ms/step - loss: 1.3275 - accuracy: 0.9038\nEpoch 103/200\n1/1 [==============================] - 1s 1s/step - loss: 1.2995 - accuracy: 0.9231\nEpoch 104/200\n1/1 [==============================] - 1s 1s/step - loss: 1.2794 - accuracy: 0.9231\nEpoch 105/200\n1/1 [==============================] - 1s 984ms/step - loss: 1.2998 - accuracy: 0.8462\nEpoch 106/200\n1/1 [==============================] - 1s 1s/step - loss: 1.2756 - accuracy: 0.8846\nEpoch 107/200\n1/1 [==============================] - 1s 987ms/step - loss: 1.2700 - accuracy: 0.8846\nEpoch 108/200\n1/1 [==============================] - 1s 1s/step - loss: 1.3164 - accuracy: 0.6923\nEpoch 109/200\n1/1 [==============================] - 1s 978ms/step - loss: 1.2855 - accuracy: 0.8269\nEpoch 110/200\n1/1 [==============================] - 1s 996ms/step - loss: 1.3099 - accuracy: 0.6538\nEpoch 111/200\n1/1 [==============================] - 1s 1s/step - loss: 1.3485 - accuracy: 0.6154\nEpoch 112/200\n1/1 [==============================] - 2s 2s/step - loss: 1.2782 - accuracy: 0.7692\nEpoch 113/200\n1/1 [==============================] - 1s 1s/step - loss: 1.3284 - accuracy: 0.6346\nEpoch 114/200\n1/1 [==============================] - 2s 2s/step - loss: 1.2721 - accuracy: 0.7500\nEpoch 115/200\n1/1 [==============================] - 1s 1s/step - loss: 1.1963 - accuracy: 0.9423\nEpoch 116/200\n1/1 [==============================] - 2s 2s/step - loss: 1.1931 - accuracy: 0.9231\nEpoch 117/200\n1/1 [==============================] - 1s 1s/step - loss: 1.1965 - accuracy: 0.8654\nEpoch 118/200\n1/1 [==============================] - 1s 1s/step - loss: 1.2010 - accuracy: 0.9038\nEpoch 119/200\n1/1 [==============================] - 2s 2s/step - loss: 1.1701 - accuracy: 0.9038\nEpoch 120/200\n1/1 [==============================] - 2s 2s/step - loss: 1.1453 - accuracy: 1.0000\nEpoch 121/200\n1/1 [==============================] - 1s 1s/step - loss: 1.1529 - accuracy: 0.9038\nEpoch 122/200\n1/1 [==============================] - 1s 1s/step - loss: 1.1813 - accuracy: 0.8077\nEpoch 123/200\n1/1 [==============================] - 1s 1s/step - loss: 1.1736 - accuracy: 0.8077\nEpoch 124/200\n1/1 [==============================] - 1s 1s/step - loss: 1.2215 - accuracy: 0.7115\nEpoch 125/200\n1/1 [==============================] - 1s 1s/step - loss: 1.5557 - accuracy: 0.3077\nEpoch 126/200\n1/1 [==============================] - 1s 993ms/step - loss: 1.2872 - accuracy: 0.5192\nEpoch 127/200\n1/1 [==============================] - 1s 1s/step - loss: 1.1056 - accuracy: 0.9808\nEpoch 128/200\n1/1 [==============================] - 1s 995ms/step - loss: 1.0848 - accuracy: 1.0000\nEpoch 129/200\n1/1 [==============================] - 1s 1s/step - loss: 1.1192 - accuracy: 0.9808\nEpoch 130/200\n1/1 [==============================] - 2s 2s/step - loss: 1.0883 - accuracy: 0.9231\nEpoch 131/200\n1/1 [==============================] - 1s 1s/step - loss: 1.0665 - accuracy: 0.9615\nEpoch 132/200\n1/1 [==============================] - 1s 1s/step - loss: 1.0550 - accuracy: 1.0000\nEpoch 133/200\n1/1 [==============================] - 1s 1s/step - loss: 1.0629 - accuracy: 0.9231\nEpoch 134/200\n1/1 [==============================] - 1s 1s/step - loss: 1.0550 - accuracy: 0.9038\nEpoch 135/200\n1/1 [==============================] - 1s 1s/step - loss: 1.0385 - accuracy: 1.0000\nEpoch 136/200\n1/1 [==============================] - 1s 1s/step - loss: 1.0990 - accuracy: 0.8269\nEpoch 137/200\n1/1 [==============================] - 2s 2s/step - loss: 1.1186 - accuracy: 0.6538\nEpoch 138/200\n1/1 [==============================] - 1s 1s/step - loss: 1.1144 - accuracy: 0.7500\nEpoch 139/200\n1/1 [==============================] - 2s 2s/step - loss: 1.1962 - accuracy: 0.6154\nEpoch 140/200\n1/1 [==============================] - 1s 1s/step - loss: 1.1791 - accuracy: 0.5577\nEpoch 141/200\n1/1 [==============================] - 1s 1s/step - loss: 1.0139 - accuracy: 0.9808\nEpoch 142/200\n1/1 [==============================] - 1s 1s/step - loss: 1.0145 - accuracy: 0.9808\nEpoch 143/200\n1/1 [==============================] - 1s 1s/step - loss: 0.9981 - accuracy: 0.9808\nEpoch 144/200\n1/1 [==============================] - 1s 1s/step - loss: 1.0095 - accuracy: 0.9423\nEpoch 145/200\n1/1 [==============================] - 1s 1s/step - loss: 1.0215 - accuracy: 0.9231\nEpoch 146/200\n1/1 [==============================] - 1s 1s/step - loss: 0.9813 - accuracy: 0.9038\nEpoch 147/200\n1/1 [==============================] - 1s 1s/step - loss: 0.9895 - accuracy: 0.9423\nEpoch 148/200\n1/1 [==============================] - 1s 1s/step - loss: 0.9468 - accuracy: 1.0000\nEpoch 149/200\n1/1 [==============================] - 1s 1s/step - loss: 0.9555 - accuracy: 0.9615\nEpoch 150/200\n1/1 [==============================] - 2s 2s/step - loss: 0.9336 - accuracy: 1.0000\nEpoch 151/200\n1/1 [==============================] - 1s 1s/step - loss: 0.9241 - accuracy: 1.0000\nEpoch 152/200\n1/1 [==============================] - 1s 1s/step - loss: 0.9271 - accuracy: 0.9808\nEpoch 153/200\n1/1 [==============================] - 1s 1s/step - loss: 0.9318 - accuracy: 0.9615\nEpoch 154/200\n1/1 [==============================] - 1s 1s/step - loss: 0.9250 - accuracy: 1.0000\nEpoch 155/200\n1/1 [==============================] - 1s 1s/step - loss: 0.9302 - accuracy: 0.9423\nEpoch 156/200\n1/1 [==============================] - 1s 1s/step - loss: 1.0445 - accuracy: 0.6346\nEpoch 157/200\n1/1 [==============================] - 1s 1s/step - loss: 1.1295 - accuracy: 0.5000\nEpoch 158/200\n1/1 [==============================] - 1s 1s/step - loss: 0.9692 - accuracy: 0.8462\nEpoch 159/200\n1/1 [==============================] - 1s 1s/step - loss: 0.9608 - accuracy: 0.8654\nEpoch 160/200\n1/1 [==============================] - 1s 1s/step - loss: 0.9288 - accuracy: 0.9231\nEpoch 161/200\n1/1 [==============================] - 1s 1s/step - loss: 0.9194 - accuracy: 0.8846\nEpoch 162/200\n1/1 [==============================] - 1s 1s/step - loss: 0.8791 - accuracy: 0.9808\nEpoch 163/200\n1/1 [==============================] - 1s 1s/step - loss: 0.8858 - accuracy: 0.9808\nEpoch 164/200\n1/1 [==============================] - 1s 1s/step - loss: 0.8805 - accuracy: 0.9423\nEpoch 165/200\n1/1 [==============================] - 2s 2s/step - loss: 0.9292 - accuracy: 0.7885\nEpoch 166/200\n1/1 [==============================] - 2s 2s/step - loss: 0.8787 - accuracy: 1.0000\nEpoch 167/200\n1/1 [==============================] - 1s 1s/step - loss: 0.8409 - accuracy: 1.0000\nEpoch 168/200\n1/1 [==============================] - 1s 1s/step - loss: 0.8294 - accuracy: 1.0000\nEpoch 169/200\n1/1 [==============================] - 1s 1s/step - loss: 0.8052 - accuracy: 1.0000\nEpoch 170/200\n1/1 [==============================] - 1s 1s/step - loss: 0.8561 - accuracy: 0.9615\nEpoch 171/200\n1/1 [==============================] - 1s 1s/step - loss: 0.9050 - accuracy: 0.8269\nEpoch 172/200\n1/1 [==============================] - 1s 1s/step - loss: 0.8664 - accuracy: 0.9038\nEpoch 173/200\n1/1 [==============================] - 1s 1s/step - loss: 0.8097 - accuracy: 0.9615\nEpoch 174/200\n1/1 [==============================] - 1s 1s/step - loss: 0.7848 - accuracy: 1.0000\nEpoch 175/200\n1/1 [==============================] - 1s 1s/step - loss: 0.7885 - accuracy: 0.9808\nEpoch 176/200\n1/1 [==============================] - 1s 1s/step - loss: 0.7803 - accuracy: 1.0000\nEpoch 177/200\n1/1 [==============================] - 1s 1s/step - loss: 0.7842 - accuracy: 0.9808\nEpoch 178/200\n1/1 [==============================] - 1s 1s/step - loss: 0.7895 - accuracy: 0.9808\nEpoch 179/200\n1/1 [==============================] - 1s 1s/step - loss: 0.7639 - accuracy: 1.0000\nEpoch 180/200\n1/1 [==============================] - 1s 1s/step - loss: 0.7477 - accuracy: 1.0000\nEpoch 181/200\n1/1 [==============================] - 1s 1s/step - loss: 0.7800 - accuracy: 0.9615\nEpoch 182/200\n1/1 [==============================] - 1s 1s/step - loss: 0.7594 - accuracy: 0.9808\nEpoch 183/200\n1/1 [==============================] - 1s 1s/step - loss: 0.7614 - accuracy: 0.9615\nEpoch 184/200\n1/1 [==============================] - 1s 1s/step - loss: 0.7827 - accuracy: 0.9423\nEpoch 185/200\n1/1 [==============================] - 1s 1s/step - loss: 0.7915 - accuracy: 0.9038\nEpoch 186/200\n1/1 [==============================] - 1s 1s/step - loss: 0.8952 - accuracy: 0.7500\nEpoch 187/200\n1/1 [==============================] - 1s 1s/step - loss: 0.8984 - accuracy: 0.7308\nEpoch 188/200\n1/1 [==============================] - 1s 1s/step - loss: 0.7711 - accuracy: 0.9423\nEpoch 189/200\n1/1 [==============================] - 1s 1s/step - loss: 0.7504 - accuracy: 0.9615\nEpoch 190/200\n1/1 [==============================] - 1s 1s/step - loss: 0.7074 - accuracy: 1.0000\nEpoch 191/200\n1/1 [==============================] - 1s 1s/step - loss: 0.6886 - accuracy: 1.0000\nEpoch 192/200\n1/1 [==============================] - 1s 1s/step - loss: 0.7200 - accuracy: 0.9808\nEpoch 193/200\n1/1 [==============================] - 1s 1s/step - loss: 0.8901 - accuracy: 0.7308\nEpoch 194/200\n1/1 [==============================] - 1s 1s/step - loss: 0.8519 - accuracy: 0.7308\nEpoch 195/200\n1/1 [==============================] - 1s 1s/step - loss: 0.7218 - accuracy: 0.9423\nEpoch 196/200\n1/1 [==============================] - 1s 1s/step - loss: 0.6701 - accuracy: 1.0000\nEpoch 197/200\n1/1 [==============================] - 1s 1s/step - loss: 0.6671 - accuracy: 1.0000\nEpoch 198/200\n1/1 [==============================] - 1s 1s/step - loss: 0.6717 - accuracy: 1.0000\nEpoch 199/200\n1/1 [==============================] - 1s 1s/step - loss: 0.6614 - accuracy: 1.0000\nEpoch 200/200\n1/1 [==============================] - 1s 1s/step - loss: 0.6402 - accuracy: 1.0000\n"
    }
   ],
   "source": [
    "\n",
    "from keras import backend as K \n",
    "K.clear_session()  #Resets all state generated by Keras\n",
    "\n",
    "latent_dim = 100\n",
    "embedding_dim = 100\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(x.shape[1],))\n",
    "\n",
    "# TODO: understand how embedding works here; is this our own trained embedding? maybe we should just use word2vec\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(X_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm\n",
    "# TODO: why are we not using an activation function? default is none, only for recurrent activation the default is sigmoid\n",
    "# TODO: why do we need the encoder_outputs? only for attention probably\n",
    "encoder_lstm = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "\n",
    "#Setting up the Decoder using 'encoder_states' as initial state\n",
    "# TODO: figure out why the shape is None? because we also use it later for our decoding when we only give one\n",
    "decoder_inputs = Input(shape=((y.shape[1] - 1),))\n",
    "\n",
    "#Embedding layer\n",
    "dec_emb_layer = Embedding(Y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "# TODO: is the LSTM bidirectional? why do we even need those two states?\n",
    "# TODO: why do the graphs say (None, 256) where 256 is the latent_dim (the length of the state vectors); shouldn't it be clear that it is (1, 256)?\n",
    "decoder_outputs ,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb ,initial_state=[state_h, state_c])\n",
    "\n",
    "# #Attention layer; removed for now\n",
    "# attn_layer = AttentionLayer(name='attention_layer')\n",
    "# attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# #Concating Attention input and Decoder LSTM output\n",
    "# decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#Dense layer\n",
    "# TODO: figure out what TimeDistributed does\n",
    "decoder_dense =  TimeDistributed(Dense(units = Y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "#Defining the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#Visualize the Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='training_model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# TODO: understand this\n",
    "#Adding Metrics\n",
    "model.compile(optimizer='rmsprop' , loss='sparse_categorical_crossentropy' , metrics=['accuracy'])\n",
    "\n",
    "#Adding Callback\n",
    "# TODO: how exactly does this work? is there an internal mapping of the string \"val_loss\" to running a test on the specified validation_data?\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "#Training the Model\n",
    "# %tensorflow_version 1.x\n",
    "# indexing is clear, removing the eos token for the decoder inpu\n",
    "# ts and removing the sos token for the decoder outputs\n",
    "# TODO: think about how exactly this is working with calculating the loss etc., maybe that's the problem\n",
    "# TODO: fit only on one example and check if model actually works\n",
    "# this creates the third dimension we need to compare to the generated output of the decoder; basically creates \"one-hot encoding\" to generate the probability distribution\n",
    "history = model.fit(\n",
    "    x = [x,y[:,:-1]], \n",
    "    y = y.reshape(y.shape[0], y.shape[1], 1)[:, 1:, :],\n",
    "    epochs=200,\n",
    "    batch_size = 5\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:Model was constructed with shape (None, 52) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 1).\nPredicted summary:  an injured officer says he was shot while trying to help an elderly man move to safetylapd provides timeline for welfare check at suspect s homesuspect paul ciancia is in critical condition and could face the death penaltypolice responded to family concern arrived at ciancia s apartment shortly after he left\n\n\n"
    }
   ],
   "source": [
    "#Building Dictionary for Source Vocabulary\n",
    "# TODO: what is happening here? we are just saving the vocabularies of the tokenizers (index -> word or word -> index maps)\n",
    "target_index_word=Y_tokenizer.index_word \n",
    "source_index_word=X_tokenizer.index_word \n",
    "target_word_index=Y_tokenizer.word_index\n",
    "\n",
    "#Testing phase\n",
    "#Encoding the input sequence to get the feature vector\n",
    "# TODO: is this what links this model to the trained model? that we use the same encoder_inputs Input object?\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "#Decoder setup\n",
    "#These tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "# TODO: remove this, probably only used for attention\n",
    "# decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
    "\n",
    "#Getting the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "\n",
    "#Setting the initial states to the states from the previous time step for better prediction\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "# TODO: remove this\n",
    "# #Attention inference\n",
    "# attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "# decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "#Adding Dense softmax layer to generate proability distribution over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) \n",
    "\n",
    "#Final Decoder model\n",
    "# TODO: how is this all linked to what we trained before? where does the parameter sharing happen?\n",
    "# TODO: why are we appending the lists instead of just writing it in one list\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])\n",
    "\n",
    "#Function defining the implementation of inference process\n",
    "def decode_sequence(input_seq):\n",
    "    #Encoding the input as state vectors\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    #Generating empty target sequence of length 1\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    #Populating the first word of target sequence with the start word\n",
    "    target_seq[0, 0] = target_word_index['sos']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_h, e_c])\n",
    "\n",
    "        #Sampling a token\n",
    "        # TODO: understand the indexing: why -1 instead of 0 as well? shouldn't the output tokens be of shape (1, 1, num_words)?\n",
    "        # TODO: I think the neurons in the dense layer start at 0 but our dictionary starts at 1, despite a one-on-one mapping from\n",
    "        # dictionary index numbers to neurons if I understand correctly; doesn't make sense to make, programm will crash if arg_max returns zero\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = target_index_word[sampled_token_index]\n",
    "        \n",
    "        if(sampled_token!='eos'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #Exit condition: either hit max length or find stop word\n",
    "        # TODO: it used to be >= (max_abstract_len - 1); why? doesn't make sense to me\n",
    "        MAX_ABSTRACT_LEN = 60\n",
    "        if (sampled_token == 'eos'  or len(decoded_sentence.split()) == MAX_ABSTRACT_LEN):\n",
    "            stop_condition = True\n",
    "\n",
    "        #Updating the target sequence (of length 1)\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        #Updating internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "#Functions to convert an integer sequence to a word sequence for summary as well as reviews \n",
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=target_word_index['sos']) and i!=target_word_index['eos']):\n",
    "            newString=newString+target_index_word[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+source_index_word[i]+' '\n",
    "    return newString\n",
    "\n",
    "#Summaries generated by the model\n",
    "\n",
    "print(\"Predicted summary:\",decode_sequence(x))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2442190599.py, line 1)",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [1070]\u001b[0;36m\u001b[0m\n\u001b[0;31m    df = pd.DataFrame((cleaned_text, stories[]))\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame((cleaned_text, stories[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1071]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabstract\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabstract\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msostok \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m eostok\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Splitting the Dataset twice to get 80% training data, 10% of validation data and 10% of test data\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['abstract'] = df['abstract'].apply(lambda x : 'sostok '+ x + ' eostok')\n",
    "\n",
    "#Splitting the Dataset twice to get 80% training data, 10% of validation data and 10% of test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_val,y_train,y_val=train_test_split(np.array(df['article']),np.array(df['abstract']),test_size=0.2,random_state=0,shuffle=True)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size = 0.5, random_state = 0, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size =200\n",
    "src_txt_length =200\n",
    "sum_txt_length = 200\n",
    "# encoder input model\n",
    "inputs = Input(shape=(src_txt_length,))\n",
    "encoder1 = Embedding(vocab_size, 128)(inputs)\n",
    "encoder2 = LSTM(128)(encoder1)\n",
    "encoder3 = RepeatVector(sum_txt_length)(encoder2)\n",
    "# decoder output model\n",
    "decoder1 = LSTM(128, return_sequences=True)(encoder3)\n",
    "outputs = TimeDistributed(Dense(vocab_size, activation='softmax'))(decoder1)\n",
    "# tie it together\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1073]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEncoderRNN\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_size, hidden_size):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m(EncoderRNN, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1074]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDecoderRNN\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_size, output_size):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m(DecoderRNN, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1075]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAttnDecoderRNN\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_size, output_size, dropout_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, max_length\u001b[38;5;241m=\u001b[39mMAX_LENGTH):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m(AttnDecoderRNN, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e26081387c8990b949948d3d3fd7f7a4bc3bad723d6b8652b3d4ab339298fb31"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python38064bit8c5ff504779d4c0db4df09f0210e7c63"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}